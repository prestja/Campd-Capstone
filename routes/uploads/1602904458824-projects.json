[{"_id":"5f83b4096afc9431765836c8","name":"Pupil Tracking for Diagnosis of Parkinson's Disease","owner":"admin","status":"open","description":"Parkinson's disease is a neurodegenerative disease, in which its symptoms do not appear until the latter years of a patient's life. As of right now, there is no completely consistent and effective manner to determine if a patient has Parkinson's during its earliest stages. However, a 2010 study shows that there is a significant link between the onset of Parkinson's Disease and a patient's post-illumination pupil response, which is essentially the change in a pupil's diameter as it contracts in the presence of various wavelengths. In order to determine the pupil's diameters, researchers and medical professionals used to have to sit in a lab for long periods of time and physically measure each frame as the pupil constricts. Therefore, our objective was to augment a working digitall system which automatically measures each pupil frame, omitting the need for medical professionals to manually fit each frame. Eventually, the goal of the program is to have it fully run on its own and generate accurate data with little effort from the user.\nFor this sub-project, the main goal was to run this program on subjects and generate fits to determine the presence of Parkinson's' disease in patients, as well as determining the reliability of the program. The data that we received from this program depicted the pupil diameters as a result of adding droplets in the eyes. The eye dropllet medication added in these experiments were intended to capture nuances of pupil movement. Once pupil diameters are measured, the pharmacokinetic modeling of the drug effect can be measured in order to determine the drug response.","link":"about:blank"},{"_id":"5f83b46f6afc9431765836c9","name":"Automated Pre-fall Detection for Fall Mitigation using a Wearable Airbag Belt","owner":"admin","status":"open","description":"Falling is the leading cause of fatal injuries in people over the age of 65. The mitigation of these falls would allow for at-risk people to be more active and confident in their ability to move. To alleviate falls, at-risk people can use an airbag belt worn at the hip. Currently, the belt uses a biophysical model to predict the occurrence of falls and subsequently deploy its airbag. However, this biophysical model can significantly be improved. In order to improve the belt's fall-detection capability, we propose the application of deep neural networks. To predict the occurrence of a fall, data was taken from an airbag belt equipped with accelerometers. This data was then passed through a convolutional neural network (CNN). After selecting the hyperparameters of the CNN using a grid search through subject-wise cross validation, the trained network achieved a sensitivity of 71.9% with a predetermined specificity of 99% for a lead time of 100 milliseconds. The model developed could be applied to wearable airbag systems and help mitigate the impact of serious falls.","link":"about:blank"},{"_id":"5f83b4836afc9431765836ca","name":"TalkMotion: Mobile Application for Generating Speech Using Simple Gestures","owner":"admin","status":"open","description":"For many around the world, holding a conversation may seem second nature. However, this simple task presents a difficult challenge for individuals facing motor impairments, such as Cerebral Palsy. Severe motor impairments often result in inability to speak and communicate. Utilizing a speech tablet is the current method that many use to produce the words they want to convey, but quickly and accurately pressing buttons and transitioning between pages on a screen is not an adequate solution for those affected by these conditions. The tablet would require rapid movements to maintain a fluid conversation and the reduced motor control would cause the time needed to declare a phrase to drastically increase. To simplify communication solutions, we propose an app called TalkMotion, which utilizes simple shakes of an android device to produce an utterance. Data collected from the device's accelerometer in the X, Y, and Z planes allows for the movement to be recorded and translated into speech. The user-friendly interface enables the personalization of the app, and the future incorporation of machine-learning will result in a substantial increase in gestures.","link":"about:blank"},{"_id":"5f83b4a66afc9431765836cb","name":"Gesture Recognition Using and LSTM Deep Learning Neural Network Trained on Accelerometer Data","owner":"admin","status":"open","description":"People all around the world suffer from the inability to verbally communicate or use sign language efficiently. Talking For this purpose, the gesture recognition effort uses LSTM's, a type of recurrent neural networks that are typically used for time series data, such as accelerometer data. The LSTM model uses the Android's built-in accelerometer and gravity sensors to detect and differentiate between different gestures. By collecting the x-axis, y-axis, and z-axis, the model classifies each gesture into their own category. It is then standardized, splint into training and testing data, and input into the bidirectional LSTM Keras model. By classifying each gesture, the model can predict each gesture based on real time coordinates of the accelerometer. This methodology allows a machine learning approach to recognize gestures and implement voice dialogue that could be implemented into a specially made wearable device for clinical use in the future. As such, the long term goal of this effort is to help speech impaired people have more natural conversation and allow them to express their ideas in a quick and efficient manner.","link":"about:blank"},{"_id":"5f83b4b76afc9431765836cc","name":"Temporal Distance Map","owner":"admin","status":"open","description":"The temporal distance map developed by Blake Albert, Christian Panici, and Nigel Castelino sought to give end users the ability to visualize maps based on the time needed to travel to different points from a center point. The project was largely a success; however, the efficacy to the project's public access and appeal is called into question based on the usage of the Mathematica and Wolfram API, so in order to make the map more accessible this project aims to make a temporal distance map using free code and APIs provided by the python language and Bing Maps API respectively. This in turn allows a wider audience to enjoy the unique visualization of maps based on travel time, rather than physical distance.","link":"about:blank"},{"_id":"5f83b4c36afc9431765836cd","name":"Dashboard System to Track Cumulative Exposure to Dangerous Sound Levels during Music Instruction","owner":"admin","status":"open","description":"A study sponsored by the National Institutes of Health (NIH) estimates that 13-18% of American youth suffer from some form of noise-induced hearing loss (NIHL). Recommendations have been put in place to promote safe listening practices for listening to music, using electronics, and other activities teenagers typically enjoy. However, one area that has been overlooked is that of music education. Studies suggest that band rehearsals can get as loud as 120 dB - for reference, guidelines published by the National Institute for Occupational Safety and Health (NIOSH) state that exposure to noises at this intensity can be hazardous after 8 seconds. Keeping that in mind, the goal of this project is to track noise exposure accumulation and present it in a format so that music educators can make informed decisions in order to protect their students' health.","link":"about:blank"},{"_id":"5f83b4d46afc9431765836ce","name":"Stock2Vec: Utilizing Embeddings for Stock-Risk Prediction","owner":"admin","status":"open","description":"Stocks are very hard to represent. From employees to business owners to product, all companies are different in many more ways than one. What if there was a way to represent each stock however with just 4 numbers? Stock2Vec utilizes Word2Vec embeddings in order to turn stocks into numerical representations consisting of many dimensions or sizes, which can easily be analyzed by Artificial Intelligence. After creating the embeddinngs, it uses a method called PCA to compress those many dimensions to 2 so we can visualize the similarities between two different stocks. After \"compression\", we found that similar stocks share similar traits or locations on the graph. Furthermore using a classifier to train the model to identify a stock's sensor based on their embedding, we found that our embedding model has a 55% accuracy across 11 sectors. By refining this model we can start to do stock-risk prediction with these embeddings.","link":"about:blank"},{"_id":"5f83b4e36afc9431765836cf","name":"A Research and Projects Portal for UNT","owner":"Mark V. Albert","status":"open","description":"The Research and Projects Portal is a web and mobile application allows professors and students to list their active or completed research projects. The UNT community could easily look at multiple projects and communicate with the owner of that project to potentially work on it. This portal helps to bring projects that might not have been previously known about to the forefront. It would also create a more collaborative environment between professionals and professors with students, helping create more professional relationships.","link":"about:blank"},{"_id":"5f83b4f16afc9431765836d0","name":"Multi-agent Hierarchical Reinforcement Learning of Strategy and Tactics in Competitive Play","owner":"admin","status":"open","description":"Reinforcement Learning has a long history in learning tactical choices in game play, however, less effort has been invested in the strategic decisions of when and how to engage. Here we create a two-level reinforcement learning model to not only learn to play games, but also to choose how to engage with opponents to maximize earnings. We choose Q-learning as a reinforcement learning algorithm combined with a multi-agent environment in which four types of learners engage in competitive play, varying the skill for engaging players and betting (strategy) as well as learning to play the game directly (tactics). Engagement behaviors innclude changing the bet amounts or withdrawing from a match. The players learn flexibly for three different games: Connect 4, Dots and Boxes, and Tic-Tac-Toe. We analyzed the behavior of these players over the course of their learning and observed a few interesting features. As expected, we saw that learners who optimize strategy and tactics outperform all learners in the long run, and learners without strategy and tactics are outperformed by all agents. More shockingly, however, we also noticed that in the beginning, learners who optimize their strategy to engage in matches outperform learners which focus on optimizing tactical game play directly, but as more games are played, the tactics learner begins to outperform the strategy learner. This dual reinforcement learning model may have further applications to similar adversarial business scenarios where strategic and tactical learning is critical.","link":"about:blank"},{"_id":"5f891568f90b7f5aa8bcf00d","name":"[TEST]Active Project","owner":"admin","status":"Active","description":"This is a test entry to observe the effects of Active status in the database.","__v":0},{"_id":"5f89157cf90b7f5aa8bcf00e","name":"[TEST]Stale Project","owner":"admin","status":"Suspended","description":"This is a test entry to observe the effects of Suspended status in the database.","__v":0},{"_id":"5f89158ff90b7f5aa8bcf00f","name":"[TEST]Old Project","owner":"admin","status":"Archived","description":"This is a test entry to observe the effects of Archived status in the database.","__v":0}]